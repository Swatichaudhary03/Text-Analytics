{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1.Create a Doc object from the file owlcreek.txt"],"metadata":{"id":"ljNGLEcn6Gek"}},{"cell_type":"code","source":["import spacy\n","# Load the small English model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Open the file and read its contents\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Check a few tokens to confirm\n","print(doc[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUqw-Wqz6w43","outputId":"230652a3-cd61-44b1-c9cb-9bd4ad7a4416"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AN OCCURRENCE AT OWL CREEK BRIDGE\n","\n","by Ambrose Bierce\n","\n","I\n","\n","A man stood upon a railroad bridge\n"]}]},{"cell_type":"markdown","source":["2. How many tokens are contained in the file?"],"metadata":{"id":"YjjNhyW17hBR"}},{"cell_type":"code","source":["import spacy\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the contents of the file\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Count the number of tokens\n","num_tokens = len(doc)\n","print(\"Number of tokens in the file:\", num_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zw7V3_ek7h6l","outputId":"56cd431c-22b2-4dcc-a493-1586f0d85cae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of tokens in the file: 4835\n"]}]},{"cell_type":"markdown","source":[" 3.How many sentences are contained in the file?\n"],"metadata":{"id":"A-SnPLiG7uXJ"}},{"cell_type":"code","source":["import spacy\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the file contents\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Count the number of sentences\n","num_sentences = len(list(doc.sents))\n","print(\"Number of sentences in the file:\", num_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzXgyYW977jS","outputId":"aaf91e3c-1aa9-4b8b-b096-0cf812895ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of sentences in the file: 204\n"]}]},{"cell_type":"markdown","source":["4.Print the second sentence in the document"],"metadata":{"id":"xWr7GlzN8DNo"}},{"cell_type":"code","source":["import spacy\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the file contents\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Convert the sentences into a list\n","sentences = list(doc.sents)\n","\n","# Print the second sentence\n","print(sentences[1].text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4FDJsBfE8Ixc","outputId":"75dea42e-94c4-4acb-bca3-2ace6f55fc9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The man's hands were behind\n","his back, the wrists bound with a cord.  \n"]}]},{"cell_type":"markdown","source":["5. For each token in the sentence above, print its text, POS tag, dep tag and lemma."],"metadata":{"id":"6hR8gIf38hCF"}},{"cell_type":"code","source":["import spacy\n","\n","# Load spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the text from the file\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create the Doc object\n","doc = nlp(text)\n","\n","# Extract the second sentence\n","sentences = list(doc.sents)\n","second_sentence = sentences[1]\n","\n","# Print token details\n","print(f\"Second sentence:\\n{second_sentence.text}\\n\")\n","print(f\"{'TOKEN':15} {'POS':10} {'DEP':15} {'LEMMA'}\")\n","print(\"-\" * 60)\n","\n","for token in second_sentence:\n","    print(f\"{token.text:15} {token.pos_:10} {token.dep_:15} {token.lemma_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFDYoRkz8q9v","outputId":"fb694dcc-f6cc-417c-dbd4-1b2cf33e3c1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Second sentence:\n","The man's hands were behind\n","his back, the wrists bound with a cord.  \n","\n","TOKEN           POS        DEP             LEMMA\n","------------------------------------------------------------\n","The             DET        det             the\n","man             NOUN       poss            man\n","'s              PART       case            's\n","hands           NOUN       nsubj           hand\n","were            AUX        ROOT            be\n","behind          ADP        prep            behind\n","\n","               SPACE      dep             \n","\n","his             PRON       poss            his\n","back            NOUN       pobj            back\n",",               PUNCT      punct           ,\n","the             DET        det             the\n","wrists          NOUN       appos           wrist\n","bound           VERB       acl             bind\n","with            ADP        prep            with\n","a               DET        det             a\n","cord            NOUN       pobj            cord\n",".               PUNCT      punct           .\n","                SPACE      dep              \n"]}]},{"cell_type":"markdown","source":[" 6.Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text."],"metadata":{"id":"skzYOEVQ9BY7"}},{"cell_type":"code","source":["import spacy\n","from spacy.matcher import Matcher\n","\n","# Load the spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the text from the file\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Initialize the Matcher with the shared vocabulary\n","matcher = Matcher(nlp.vocab)\n","\n","# Define the pattern for \"swimming vigorously\"\n","pattern = [\n","    {\"LOWER\": \"swimming\"},       # Match the word \"swimming\" (case-insensitive)\n","    {\"LOWER\": \"vigorously\"}      # Match the word \"vigorously\"\n","]\n","\n","# Add the pattern to the matcher with the name \"Swimming\"\n","matcher.add(\"Swimming\", [pattern])\n","\n","# Apply the matcher to the doc\n","matches = matcher(doc)\n","\n","# Print the matches\n","for match_id, start, end in matches:\n","    span = doc[start:end]\n","    print(f\"Match found: '{span.text}' at position {start}-{end}\")"],"metadata":{"id":"mwKk-OW89DBe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7.Print the text surrounding each found match."],"metadata":{"id":"gmZGvYZZ9dG-"}},{"cell_type":"code","source":["import spacy\n","from spacy.matcher import Matcher\n","\n","# Load spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Read the file contents\n","with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","# Create a Doc object\n","doc = nlp(text)\n","\n","# Initialize the Matcher\n","matcher = Matcher(nlp.vocab)\n","\n","# Define the pattern for \"swimming vigorously\"\n","pattern = [\n","    {\"LOWER\": \"swimming\"},\n","    {\"LOWER\": \"vigorously\"}\n","]\n","\n","# Add the pattern to the matcher\n","matcher.add(\"Swimming\", [pattern])\n","\n","# Apply the matcher\n","matches = matcher(doc)\n","\n","# Print matches with surrounding context\n","for match_id, start, end in matches:\n","    span = doc[start:end]\n","\n","    # Get context window (5 tokens before and after)\n","    context_start = max(start - 5, 0)\n","    context_end = min(end + 5, len(doc))\n","    context = doc[context_start:context_end]\n","\n","    print(f\"\\nðŸ‘‰ Match found: '{span.text}'\")\n","    print(f\"Context: {context.text}\")\n"],"metadata":{"id":"k524jBHR9ijG"},"execution_count":null,"outputs":[]}]}
